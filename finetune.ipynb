{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:02.676775Z",
     "start_time": "2023-12-24T21:07:56.592614Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "xydZ41YoB1820oiKThQfFl",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "# Import accuracy_score to check performance\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:06.550547Z",
     "start_time": "2023-12-24T21:08:06.523787Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "labeled_data = pd.read_csv('cleaned_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data\n",
    "and get an overview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:07.302061Z",
     "start_time": "2023-12-24T21:08:07.296119Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0    As a woman you shouldn't complain about clea...  \n",
      "1    boy dats cold...tyga dwn bad for cuffin dat ...  \n",
      "2   Dawg  You ever fuck a bitch and she start to ...  \n",
      "3             GAnderson based she look like a tranny  \n",
      "4    The shit you hear about me might be true or ...  \n"
     ]
    }
   ],
   "source": [
    "print(labeled_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:07.980252Z",
     "start_time": "2023-12-24T21:08:07.944747Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "GwD3nzQflDGqjPAbN1ABRP",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "labeled_data=pd.read_csv(\"labeled_data.csv\",names=[\"hate_speech\",\"offensive_language\",\"neither\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:08.808751Z",
     "start_time": "2023-12-24T21:08:08.800893Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "EaDM2y8xVXDjUKBwOgXpMh",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <td>neither</td>\n",
       "      <td>class</td>\n",
       "      <td>tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25291.0</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25292.0</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25294.0</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25295.0</th>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25296.0</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24784 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             hate_speech offensive_language  \\\n",
       "NaN     count hate_speech offensive_language     neither              class   \n",
       "0.0     3     0           0                            3                  2   \n",
       "1.0     3     0           3                            0                  1   \n",
       "2.0     3     0           3                            0                  1   \n",
       "3.0     3     0           2                            1                  1   \n",
       "...                                                  ...                ...   \n",
       "25291.0 3     0           2                            1                  1   \n",
       "25292.0 3     0           1                            2                  2   \n",
       "25294.0 3     0           3                            0                  1   \n",
       "25295.0 6     0           6                            0                  1   \n",
       "25296.0 3     0           0                            3                  2   \n",
       "\n",
       "                                                                                        neither  \n",
       "NaN     count hate_speech offensive_language                                              tweet  \n",
       "0.0     3     0           0                   !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1.0     3     0           3                   !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2.0     3     0           3                   !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3.0     3     0           2                   !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "...                                                                                         ...  \n",
       "25291.0 3     0           2                   you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "25292.0 3     0           1                   you've gone and broke the wrong heart baby, an...  \n",
       "25294.0 3     0           3                   young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "25295.0 6     0           6                               youu got wild bitches tellin you lies  \n",
       "25296.0 3     0           0                   ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24784 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:09.705525Z",
     "start_time": "2023-12-24T21:08:09.700228Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "H9nTKaGmSo16ViSCw1nZ3T",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 24784 entries, (nan, 'count', 'hate_speech', 'offensive_language') to (25296.0, '3', '0', '0')\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   hate_speech         24784 non-null  object\n",
      " 1   offensive_language  24784 non-null  object\n",
      " 2   neither             24784 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "labeled_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:10.212828Z",
     "start_time": "2023-12-24T21:08:10.206744Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "uJNZrvYheXDL8S6ek2F1eJ",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hate_speech\n",
       "0          18892\n",
       "3           2790\n",
       "1           1694\n",
       "2           1200\n",
       "6            103\n",
       "5             54\n",
       "4             35\n",
       "9              5\n",
       "8              5\n",
       "7              5\n",
       "neither        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data[\"hate_speech\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "WXYqCwPAKFFZVZJGm15r7e",
     "type": "MD"
    }
   },
   "source": [
    "Train and test split \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:11.789060Z",
     "start_time": "2023-12-24T21:08:11.784252Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "PF2ePvgxCyFbtBcYJd6YvW",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(labeled_data[\"hate_speech\"], labeled_data[\"offensive_language\"], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "DWZWWLNiF465HgtIwrL45G",
     "type": "MD"
    }
   },
   "source": [
    "we will tokenize the review text using a tokenizer.\n",
    "\n",
    "\n",
    "The labels for the reviews are converted to one-dimensional numpy arrays.\n",
    "\n",
    "The tokenized ids are stored in a dictionary with the key `input_ids` and the labels are stored in a numpy array with the key `labels`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:14.136059Z",
     "start_time": "2023-12-24T21:08:13.512417Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "5spaSLd93IYexzQYiXWYJb",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101 121 102]\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer from a pretrained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "#should be the same name from hugging face library\n",
    "\n",
    "# Tokenize the reviews\n",
    "tokenized_data_train = tokenizer(X_train.to_list(), return_tensors=\"np\", padding=True)\n",
    "tokenized_data_test = tokenizer(X_test.to_list(), return_tensors=\"np\", padding=True)\n",
    "\n",
    "# Labels are one-dimensional numpy or tensorflow array of integers\n",
    "labels_train = np.array(y_train)\n",
    "labels_test = np.array(y_test)\n",
    "\n",
    "# Tokenized ids\n",
    "print(tokenized_data_train[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:14.352216Z",
     "start_time": "2023-12-24T21:08:14.346827Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "z7jBelzlsXirncFFyKBOq7",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# COMPILE AND FIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "oEgp8pkgVuiJL3H111kqJJ",
     "type": "MD"
    }
   },
   "source": [
    "we will load the pretrained model from the Hugging Face library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:17.695040Z",
     "start_time": "2023-12-24T21:08:16.067697Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "6bFQfy1EvYgCSwYRCRaLxa",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "uqKMLtQ4fT4oQAHekuiIkD",
     "type": "MD"
    }
   },
   "source": [
    "we will compile and fit the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:19.449901Z",
     "start_time": "2023-12-24T21:08:19.432681Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "QOaaGfXek0TifoSBSPsBye",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(5e-6), loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:30.428453Z",
     "start_time": "2023-12-24T21:08:20.161104Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "RyxhqERp15bH6NWp9a4jwm",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-24 22:08:29.618679: W tensorflow/core/framework/op_kernel.cc:1816] OP_REQUIRES failed at cast_op.cc:122 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node Cast_1 defined at (most recent call last):\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2768, in run_cell\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2814, in _run_cell\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_cell_async\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n\n  File \"/var/folders/wd/fzj4fynx73l9ts0177tlxx2h0000gn/T/ipykernel_26646/3829612637.py\", line 2, in <module>\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1679, in train_step\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/metrics/base_metric.py\", line 708, in update_state\n\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_36218]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenized_data_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenized_data_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/r-miniconda-arm64/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node Cast_1 defined at (most recent call last):\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2768, in run_cell\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2814, in _run_cell\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_cell_async\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n\n  File \"/var/folders/wd/fzj4fynx73l9ts0177tlxx2h0000gn/T/ipykernel_26646/3829612637.py\", line 2, in <module>\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1679, in train_step\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n\n  File \"/Users/davidrothschild/Library/r-miniconda-arm64/lib/python3.9/site-packages/keras/src/metrics/base_metric.py\", line 708, in update_state\n\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_36218]"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(dict(tokenized_data_train),\n",
    "          labels_train,\n",
    "          validation_data=(dict(tokenized_data_test), labels_test),\n",
    "          batch_size=4,\n",
    "          epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "YKZqPonhcrGVvZsIxypOb6",
     "type": "MD"
    }
   },
   "source": [
    "All the weights will be updated by default for the transfer learning model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "u8FRdXWVKM9wDbVs3e5DVI",
     "type": "MD"
    }
   },
   "source": [
    "We run the predictions on the test data and get the predicted probabilities and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:46.717958Z",
     "start_time": "2023-12-24T21:08:35.402500Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "WbOfwmUHYIALorSWU599YX",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 11s 66ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.36553594, 0.30390155],\n",
       "       [0.41226524, 0.30849582],\n",
       "       [0.41226524, 0.30849582],\n",
       "       [0.41226524, 0.30849582],\n",
       "       [0.41226524, 0.30849582]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "y_test_predict = model.predict(dict(tokenized_data_test))['logits']\n",
    "\n",
    "# First 5 predictions\n",
    "y_test_predict[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "nmmgpRIjcUG71ZkqZZp0bT",
     "type": "MD"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:46.723238Z",
     "start_time": "2023-12-24T21:08:46.718811Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "tWSm43gFbHk9XL6Npuwltq",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[0.51540375, 0.48459628],\n",
       "       [0.5259191 , 0.47408086],\n",
       "       [0.5259191 , 0.47408086],\n",
       "       [0.5259191 , 0.47408086],\n",
       "       [0.5259191 , 0.47408086]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted probabilities\n",
    "y_test_probabilities = tf.nn.softmax(y_test_predict)\n",
    "\n",
    "# First 5 predicted probabilities\n",
    "y_test_probabilities[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "8MaLpFUi34IWwl8k2ijBBm",
     "type": "MD"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:49.882677Z",
     "start_time": "2023-12-24T21:08:49.875602Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "UGzlVhx8nAy5wOJuJenCIU",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted label\n",
    "y_test_class_preds = np.argmax(y_test_probabilities, axis=1)\n",
    "\n",
    "# First 5 predicted labels\n",
    "y_test_class_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "4MI308HfWXkDQmhgNxZ2gL",
     "type": "MD"
    }
   },
   "source": [
    "We can check the accuracy of the model by comparing the predicted labels with the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T21:08:54.189170Z",
     "start_time": "2023-12-24T21:08:54.183004Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "eEff3NBkfp1FNqWDR5s3kU",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_class_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T12:06:16.980931Z",
     "start_time": "2023-12-21T12:06:16.853407Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/r-miniconda-arm64/lib/python3.9/site-packages/sklearn/utils/_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/r-miniconda-arm64/lib/python3.9/site-packages/sklearn/utils/_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[0;32m~/Library/r-miniconda-arm64/lib/python3.9/site-packages/sklearn/utils/_encode.py:165\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[0;32m~/Library/r-miniconda-arm64/lib/python3.9/site-packages/sklearn/utils/_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m y_test_encoded \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(y_test)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Transform the predictions (do not fit again!)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m y_test_class_preds_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_class_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m rint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, conf_matrix)\n",
      "File \u001b[0;32m~/Library/r-miniconda-arm64/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/r-miniconda-arm64/lib/python3.9/site-packages/sklearn/utils/_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 1"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the true labels\n",
    "y_test_encoded = le.fit_transform(y_test)\n",
    "\n",
    "# Transform the predictions (do not fit again!)\n",
    "y_test_class_preds_encoded = le.transform(y_test_class_preds)\n",
    "rint(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "xaaqmPtaQyKGV0yhLcOEFG",
     "type": "MD"
    }
   },
   "source": [
    "We save the model and the tokenizer, so that we can use it later.\n",
    "\n",
    "\n",
    "`tokenizer.save_pretrained` saves the tokenizer information to the drive and `model.save_pretrained` saves the model to the drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T12:06:20.641135Z",
     "start_time": "2023-12-21T12:06:19.961350Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "0WJ8Xoa1EEH0DTkI4jaOB3",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('./sentiment_transfer_learning_tensorflow/')\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained('./sentiment_transfer_learning_tensorflow/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "wB3mew3UJchygVaRRwoYkd",
     "type": "MD"
    }
   },
   "source": [
    "We can zip the folder and download it to our local drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T21:01:43.174835Z",
     "start_time": "2023-12-20T21:01:28.790336Z"
    },
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "8M9kBGiWCR9paQRKjiw0ha",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: sentiment_transfer_learning_tensorflow/ (stored 0%)\n",
      "updating: sentiment_transfer_learning_tensorflow/tokenizer_config.json (deflated 76%)\n",
      "updating: sentiment_transfer_learning_tensorflow/special_tokens_map.json (deflated 42%)\n",
      "updating: sentiment_transfer_learning_tensorflow/config.json (deflated 47%)\n",
      "updating: sentiment_transfer_learning_tensorflow/tokenizer.json (deflated 70%)\n",
      "updating: sentiment_transfer_learning_tensorflow/vocab.txt (deflated 49%)\n",
      "updating: sentiment_transfer_learning_tensorflow/tf_model.h5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (deflated 7%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r sentiment_transfer_learning_tensorflow.zip sentiment_transfer_learning_tensorflow/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "Dyvd5OPhpmXO8Ne8ob4sp6",
     "type": "MD"
    }
   },
   "source": [
    "if you are using google colab, you can easily connect and copy your zip file (model) to any directory of your google drive"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "report_row_ids": [],
   "version": 3
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
